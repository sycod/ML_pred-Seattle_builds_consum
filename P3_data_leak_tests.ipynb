{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Estimateurs : comparaison et recherche de fuite](#toc1_)    \n",
    "- [Tableau comparatif](#toc2_)    \n",
    "- [M√©thode pas √† pas](#toc3_)    \n",
    "- [Enregistrement des traitements](#toc4_)    \n",
    "- [Scores (r2) selon les traitements](#toc5_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=1\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pickle\n",
    "import time\n",
    "from functools import partial\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# render in GitHub & NBViewer\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "\n",
    "# prevent warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# logging configuration (see all outputs, even DEBUG or INFO)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_PATH = \"./\"\n",
    "dataset_name = \"oc_p3_2016_Building_Energy_Benchmarking.csv\"\n",
    "data_raw = pd.read_csv(DATASETS_PATH+dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_warn(df, nan_col=\"nan_pct\", tags_col=\"tags\", thresh=0.4):\n",
    "    \"\"\"\n",
    "    Warns if NaNs outpass a defined threshold,\n",
    "    warning showed as a tag in the dataframe on a defined column.\n",
    "\n",
    "    Inputs:\n",
    "    ‚Ä¢ df: dataframe\n",
    "    ‚Ä¢ nan_col: dataframe column (string, default = \"nan\")\n",
    "    ‚Ä¢ tags_col: dataframe column (string, default = \"tags\")\n",
    "    ‚Ä¢ thresh: threshold for NaNs warning (float, default = 0.4)\n",
    "\n",
    "    Output: modified dataframe\n",
    "\n",
    "    Requirements: pandas\n",
    "    \"\"\"\n",
    "\n",
    "    df_ = df.copy()\n",
    "    mask = df_[nan_col] / 100 >= thresh\n",
    "    df_.loc[mask, tags_col] = df_.loc[mask, tags_col] + \"üö´\"\n",
    "\n",
    "    return df_\n",
    "\n",
    "def type_tag(df, uni_col=\"unique\", type_col=\"type\", count_col=\"count\",\n",
    "    tags_col=\"tags\"):\n",
    "    \"\"\"\n",
    "    Defines a type tag of a dataframe feature,\n",
    "    depending on unique values, count and dtype,\n",
    "    and writes it in a tag column.\n",
    "\n",
    "    Inputs:\n",
    "    ‚Ä¢ df: dataframe\n",
    "    ‚Ä¢ uni_col: dataframe column (string, default = \"unique\")\n",
    "    ‚Ä¢ type_col: dataframe column (string, default = \"type\")\n",
    "    ‚Ä¢ count_col: dataframe column (string, default = \"type\")\n",
    "    ‚Ä¢ tags_col: dataframe column (string, default = \"tags\")\n",
    "\n",
    "    Output: modified dataframe\n",
    "\n",
    "    Requirements: pandas\n",
    "    \"\"\"\n",
    "\n",
    "    df_ = df.copy()\n",
    "    total_count = max(df_[count_col])\n",
    "\n",
    "    # const warn\n",
    "    const_mask = df_[uni_col] == 1\n",
    "    df_.loc[const_mask, tags_col] = df_.loc[const_mask, tags_col] + \"üîí\"\n",
    "\n",
    "    # unique warn\n",
    "    uniq_mask = df_[uni_col] == total_count\n",
    "    df_.loc[uniq_mask, tags_col] = df_.loc[uniq_mask, tags_col] + \"üíé\"\n",
    "\n",
    "    # bool = categorical feat\n",
    "    is_bool_mask = df_[type_col] == \"bool\"\n",
    "    df_.loc[is_bool_mask, tags_col] = df_.loc[is_bool_mask, tags_col] + \"üì¶\"\n",
    "    \n",
    "    # object categorical feat\n",
    "    type_mask = df_[type_col] == \"object\"\n",
    "    # define limit\n",
    "    categ_limit = int(max(2, min(60, total_count / 1.2)))\n",
    "    # filter\n",
    "    categ_mask = df_[uni_col].between(2, categ_limit)\n",
    "    df_.loc[(categ_mask & type_mask), tags_col] = df_.loc[\n",
    "        (categ_mask & type_mask), tags_col] + \"üì¶\"\n",
    "\n",
    "    return df_\n",
    "\n",
    "def describe_df(df, nan_thresh=0.4):\n",
    "    \"\"\"\n",
    "    Dataframe describer, include little more information than .describe()\n",
    "\n",
    "    Inputs:\n",
    "    ‚Ä¢ df: dataframe to be analysed\n",
    "    ‚Ä¢ nan_thresh: threshold for NaNs warning (float, default = 0.4)\n",
    "\n",
    "    Output: dataframe of data description\n",
    "\n",
    "    Requirements: pandas, numpy\n",
    "    \"\"\"\n",
    "\n",
    "    df_ = df.describe(include=\"all\").T\n",
    "    df_.sort_index(inplace=True)\n",
    "    df_[\"unique\"] = df.nunique()\n",
    "    df_[\"type\"] = df.dtypes\n",
    "    df_[\"nan\"] = df.isna().sum()\n",
    "    df_[\"nan_pct\"] = np.round(df.isna().mean()*100, 2)\n",
    "    \n",
    "    # tags column\n",
    "    df_.insert(0, \"tags\", \"\")\n",
    "    # nan warning tag\n",
    "    df_ = nan_warn(df_, thresh=nan_thresh)\n",
    "    # type check + const warn tag\n",
    "    df_ = type_tag(df_,\n",
    "        uni_col=\"unique\",\n",
    "        type_col=\"type\",\n",
    "        count_col=\"count\",\n",
    "        tags_col=\"tags\",\n",
    "    )\n",
    "    \n",
    "    df_ = df_.fillna(\"-\")\n",
    "\n",
    "    return df_\n",
    "\n",
    "def impact_classif(value, thresh=30):\n",
    "    \"\"\"\n",
    "    Returns an impact classification depending on a value\n",
    "    and a threshold.\n",
    "\n",
    "    Positional arguments: \n",
    "    -------------------------------------\n",
    "    value: float or int: between 0 and 100\n",
    "\n",
    "    Optional arguments: \n",
    "    -------------------------------------\n",
    "    thresh: float or int: threshold to adjust the function, default=30\n",
    "\n",
    "    Output: string, warning intensity (int)\n",
    "    \"\"\"\n",
    "\n",
    "    if value == 0:\n",
    "        return \"‚åÄ\", False\n",
    "    elif 0 < value < (thresh / 6):\n",
    "        return \"--\", False\n",
    "    elif (thresh / 6) <= value < (thresh / 3):\n",
    "        return \"-\", False\n",
    "    elif (thresh / 3) <= value < (thresh * 2 / 3):\n",
    "        return \"+\", False\n",
    "    elif (thresh * 2 / 3) <= value < thresh:\n",
    "        return \"++\", False\n",
    "    elif thresh <= value < (thresh + (thresh / 3)):\n",
    "        return \"‚ö†Ô∏è\", 1\n",
    "    elif (thresh + (thresh / 3)) <= value < (thresh + (2 * thresh / 3)):\n",
    "        return \"‚ö†Ô∏è‚ö†Ô∏è\", 2\n",
    "    elif (thresh + (2 * thresh / 3)) <= value < 75:\n",
    "        return \"‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è\", 3\n",
    "    elif value >= 75:\n",
    "        return \"‚ò†Ô∏è\", 4\n",
    "    else:\n",
    "        return \"‚ùì\", False\n",
    "\n",
    "def impact(df_before, df_after, monitored=None):\n",
    "    \"\"\"\n",
    "    Returns an impact dataframe from an original and\n",
    "    a second dataframe.\n",
    "    Impact is calculated on the columns and population,\n",
    "    plus on some optional arguments.\n",
    "\n",
    "    Positional arguments: \n",
    "    -------------------------------------\n",
    "    df_before: dataframe: original dataframe (starting point, before action)\n",
    "    df_before: dataframe: original dataframe (starting point, after action)\n",
    "\n",
    "    Optional arguments: \n",
    "    -------------------------------------\n",
    "    monitored: list of strings: Columns to check.\n",
    "               ‚ö†Ô∏è Columns must be present in both dataframes.\n",
    "               Default = None\n",
    "\n",
    "    Output: dataframe in logging.info()\n",
    "\n",
    "    Required modules: pandas, numpy, logging\n",
    "    \"\"\"\n",
    "\n",
    "    pop_bef = df_before.shape[0]\n",
    "    cols_bef = df_before.shape[1]\n",
    "    \n",
    "    pop_aft = df_after.shape[0]\n",
    "    cols_aft = df_after.shape[1]\n",
    "\n",
    "    diff_pop = pop_bef - pop_aft\n",
    "    diff_cols = cols_bef - cols_aft\n",
    "\n",
    "    prct_pop_num = np.round(diff_pop / pop_bef * 100, 2)\n",
    "    prct_cols_num = np.round(diff_cols / cols_bef * 100, 2)\n",
    "    prct_pop = f\"{prct_pop_num}%\"\n",
    "    prct_cols = f\"{prct_cols_num}%\"\n",
    "\n",
    "    imp_cols = impact_classif(prct_cols_num)\n",
    "    imp_pop = impact_classif(prct_pop_num)\n",
    "\n",
    "    # list of potential warnings\n",
    "    warn_logs = [imp_cols[1], imp_pop[1]]\n",
    "\n",
    "    _df_ = pd.DataFrame([\n",
    "        [cols_bef, pop_bef],\n",
    "        [cols_aft, pop_aft],\n",
    "        [diff_cols, diff_pop],\n",
    "        [prct_cols, prct_pop],\n",
    "        [imp_cols[0], imp_pop[0]]],\n",
    "        columns=[\"Columns\", \"Population\"],\n",
    "        index=[\"Before\", \"After\", \"Difference\", \"Prct\", \"IMPACT\"]\n",
    "    )\n",
    "    \n",
    "\n",
    "    if monitored:\n",
    "        for m in monitored:\n",
    "            # get output from command\n",
    "            before_ = df_before[m].count()\n",
    "            after_ = df_after[m].count()\n",
    "            prct_ = np.round((before_ - after_) / before_ * 100, 2)\n",
    "            imp = impact_classif(prct_)\n",
    "            # add in DF\n",
    "            _df_[m] = [before_,\n",
    "                    after_,\n",
    "                    before_ - after_,\n",
    "                    f\"{prct_}%\",\n",
    "                    imp[0]\n",
    "            ]\n",
    "            # add potential warning\n",
    "            warn_logs.append(imp[1])\n",
    "\n",
    "    if (1 in warn_logs or 2 in warn_logs or 3 in warn_logs):\n",
    "        return logging.warning(display(_df_))\n",
    "    elif 4 in warn_logs:\n",
    "        return logging.critical(display(_df_))\n",
    "    else:\n",
    "        return logging.info(display(_df_))\n",
    "\n",
    "def data_cleaner(df, min_nr_pct=0.0001, verbose=False):\n",
    "    \"\"\"\n",
    "\n",
    "    Data cleaning, grouping explicitly all previously used cleaning methods.\n",
    "\n",
    "    Input: dataframe\n",
    "    Output: cleansed dataframe\n",
    "\n",
    "    Requirements: numpy, pandas, logging\n",
    "    \"\"\"\n",
    "\n",
    "    # DROP DUPLICATES\n",
    "    # *************************************************************************\n",
    "    df_ = df.drop_duplicates()\n",
    "\n",
    "    # KEEP COMPLIANT DATA ONLY\n",
    "    # *************************************************************************\n",
    "    df_ = df_.loc[df_[\"ComplianceStatus\"] == \"Compliant\"]\n",
    "\n",
    "    # CLEAN NEIGHBORHOOD\n",
    "    # *************************************************************************\n",
    "    # case harmonization\n",
    "    df_[\"Neighborhood\"] = df_[\"Neighborhood\"].str.upper()\n",
    "    # duplicate deletion\n",
    "    df_.loc[df_[\"Neighborhood\"] == \"DELRIDGE NEIGHBORHOODS\",\n",
    "        \"Neighborhood\"] = \"DELRIDGE\"\n",
    "    \n",
    "    # DELETE USELESS FEATURES\n",
    "    # *************************************************************************\n",
    "    df_.drop([\n",
    "        \"Address\",\n",
    "        \"City\",\n",
    "        \"Comments\",\n",
    "        \"ComplianceStatus\",\n",
    "        \"CouncilDistrictCode\",\n",
    "        \"DataYear\",\n",
    "        \"DefaultData\",\n",
    "        # 'Electricity(kBtu)',\n",
    "        \"Electricity(kWh)\",\n",
    "        # \"ENERGYSTARScore\",\n",
    "        # 'GHGEmissionsIntensity',\n",
    "        \"Latitude\",\n",
    "        \"ListOfAllPropertyUseTypes\",\n",
    "        \"Longitude\",\n",
    "        # 'NaturalGas(kBtu)',\n",
    "        \"NaturalGas(therms)\",\n",
    "        # \"Neighborhood\",\n",
    "        # \"NumberofBuildings\",\n",
    "        # \"NumberofFloors\",\n",
    "        \"OSEBuildingID\",\n",
    "        \"Outlier\",\n",
    "        # 'PropertyGFABuilding(s)',\n",
    "        # 'PropertyGFAParking',\n",
    "        # 'PropertyGFATotal',\n",
    "        \"PropertyName\",\n",
    "        \"SiteEnergyUse(kBtu)\",\n",
    "        \"SiteEnergyUseWN(kBtu)\",\n",
    "        \"SiteEUI(kBtu/sf)\",\n",
    "        # 'SiteEUIWN(kBtu/sf)',\n",
    "        \"SourceEUI(kBtu/sf)\",\n",
    "        \"SourceEUIWN(kBtu/sf)\",\n",
    "        \"State\",\n",
    "        # 'SteamUse(kBtu)',\n",
    "        \"TaxParcelIdentificationNumber\",\n",
    "        \"TotalGHGEmissions\",\n",
    "        # 'YearBuilt',\n",
    "        \"YearsENERGYSTARCertified\",\n",
    "        \"ZipCode\",\n",
    "        ], axis=1, inplace=True)\n",
    "    \n",
    "    # BUILDING RATIO\n",
    "    # *************************************************************************\n",
    "    df_[\"BuildingRatio\"] = df_[\"PropertyGFABuilding(s)\"]\\\n",
    "        / df_[\"PropertyGFATotal\"]\n",
    "    \n",
    "    # PARKING RATIO\n",
    "    # *************************************************************************\n",
    "    # df_[\"pkg_gfa\"] = 0\n",
    "    # # seek parking GFA and add up\n",
    "    # cols = [\"ThirdLargestPropertyUseType\", \"SecondLargestPropertyUseType\",\n",
    "    #     \"LargestPropertyUseType\"]\n",
    "    # for c in cols:\n",
    "    #     gfa = c + \"GFA\"\n",
    "    #     is_pkg = df_[c].str.lower().str.contains(r'parking', na=False)\n",
    "    #     df_[gfa].where(is_pkg, 0, inplace=True)\n",
    "    #     # add GFA to total\n",
    "    #     df_[\"pkg_gfa\"] += df_[gfa]\n",
    "    # # keep highest GFA\n",
    "    # df_.loc[df_[\"pkg_gfa\"] > df_[\"PropertyGFAParking\"],\n",
    "    #     \"PropertyGFAParking\"] = df_[\"pkg_gfa\"]\n",
    "    # # apply % on total GFA\n",
    "    # df_[\"ParkingRatio\"] = df_[\"PropertyGFAParking\"] / df_[\"PropertyGFATotal\"]\n",
    "    # df_.drop([\"pkg_gfa\"], axis=1, inplace=True)\n",
    "\n",
    "    # NON-RESIDENTIAL RATIO (ALL USAGE FEATS COMPILATION)\n",
    "    # *************************************************************************\n",
    "    # df_[\"non_res_gfa\"] = 0\n",
    "    # lput_notna = df_[\"LargestPropertyUseType\"] != np.NaN\n",
    "    # cols = [\"ThirdLargestPropertyUseType\", \"SecondLargestPropertyUseType\",\n",
    "    #     \"LargestPropertyUseType\"\n",
    "    # ]\n",
    "    # # LargestPropertyUseType != NaN\n",
    "    # for c in cols:\n",
    "    #     gfa = c + \"GFA\"\n",
    "    #     is_res = df_[c].str.lower().str.contains(\n",
    "    #         r'(?<!(non))(residential|multifamily|residence)', na=True)\n",
    "    #     df_[gfa].mask(lput_notna & is_res, 0, inplace=True)\n",
    "    #     # add GFA to total\n",
    "    #     df_[\"non_res_gfa\"] += df_[gfa]\n",
    "    # # LargestPropertyUseType == NaN\n",
    "    # zero_non_res_gfa = df_[\"non_res_gfa\"] != 0\n",
    "    # is_res = df_[\"PrimaryPropertyType\"].str.lower().str.contains(\n",
    "    #     r'(?<!(non))(residential|multifamily|residence)', na=True)\n",
    "    # df_[\"non_res_gfa\"].where(lput_notna & is_res | zero_non_res_gfa,\n",
    "    #     df_[\"PropertyGFATotal\"], inplace=True)\n",
    "    # # apply % on total GFA\n",
    "    # df_[\"NonResidentialRatio\"] = df_[\"non_res_gfa\"] / df_[\"PropertyGFATotal\"]\n",
    "    # df_.loc[df_[\"NonResidentialRatio\"] > 1, \"NonResidentialRatio\"] = 1\n",
    "    # df_.drop([\"non_res_gfa\"], axis=1, inplace=True)\n",
    "\n",
    "    # DROP POPULATION UNDER A NON-RESIDENTIAL RATIO\n",
    "    # *************************************************************************\n",
    "    # df_ = df_.loc[(df_[\"NonResidentialRatio\"] >= min_nr_pct)]\n",
    "\n",
    "    # CHANGE RAW ENERGY VALUES TO ENERGY INTENSITY\n",
    "    # *************************************************************************\n",
    "    # df_[\"SteamUse_I(kBtu/sf)\"] = df_[\"SteamUse(kBtu)\"]\\\n",
    "    #     / df_[\"PropertyGFATotal\"]\n",
    "    # df_[\"Electricity_I(kBtu/sf)\"] = df_[\"Electricity(kBtu)\"]\\\n",
    "    #     / df_[\"PropertyGFATotal\"]\n",
    "    df_[\"NaturalGas_I(kBtu/sf)\"] = df_[\"NaturalGas(kBtu)\"]\\\n",
    "        / df_[\"PropertyGFATotal\"]\n",
    "        \n",
    "    # SET MINIMUM NUMBER OF FLOORS TO 1 AND ADD AREA PER FLOOR FEATURE\n",
    "    # *************************************************************************\n",
    "    df_.loc[(df_[\"NumberofFloors\"] == 0) & (df_[\"BuildingRatio\"] > 0),\n",
    "        \"NumberofFloors\"] = 1\n",
    "    df_[\"AreaPerFloor(sf)\"] = df_[\"NumberofFloors\"]\\\n",
    "        / df_[\"PropertyGFATotal\"]\n",
    "\n",
    "    # SET MINIMUM NUMBER OF BUILDINGS TO 1 AND ADD AREA PER BUILDING FEATURE\n",
    "    # *************************************************************************\n",
    "    df_.loc[(df_[\"NumberofBuildings\"] == 0) & (df_[\"BuildingRatio\"] > 0),\n",
    "        \"NumberofBuildings\"] = 1\n",
    "    df_[\"AreaPerBldg(sf)\"] = df_[\"NumberofBuildings\"]\\\n",
    "        / df_[\"PropertyGFATotal\"]\n",
    "\n",
    "    # CHASE STATISTICAL OUTLIERS\n",
    "    # *************************************************************************\n",
    "    df_ = df_.loc[df_[\"GHGEmissionsIntensity\"] <= 20] # 2 individuals\n",
    "    df_ = df_.loc[df_[\"AreaPerFloor(sf)\"] <= 0.004] # 1 individual\n",
    "    # df_ = df_.loc[df_[\"BuildingRatio\"] >= 0.4] # 19 individuals\n",
    "    df_ = df_.loc[df_[\"NumberofBuildings\"] <= 20] # 3 individuals\n",
    "    df_ = df_.loc[df_[\"NumberofFloors\"] <= 40] # 16 individuals\n",
    "    # df_ = df_.loc[df_[\"ParkingRatio\"] <= 0.8] # 8 individuals\n",
    "    df_ = df_.loc[df_[\"PropertyGFATotal\"] <= 2000000] # 1 individual\n",
    "    # df_ = df_.loc[df_[\"SteamUse_I(kBtu/sf)\"] <= 100] # 6 individuals\n",
    "    # df_ = df_.loc[df_[\"Electricity_I(kBtu/sf)\"] <= 350] # 6 individuals\n",
    "\n",
    "    # DELETE LAST USELESS FEATURES\n",
    "    # *************************************************************************\n",
    "    df_.drop([\n",
    "        \"BuildingType\",\n",
    "        \"PrimaryPropertyType\",\n",
    "        \"LargestPropertyUseType\",\n",
    "        \"LargestPropertyUseTypeGFA\",\n",
    "        \"SecondLargestPropertyUseType\",\n",
    "        \"SecondLargestPropertyUseTypeGFA\",\n",
    "        \"ThirdLargestPropertyUseType\",\n",
    "        \"ThirdLargestPropertyUseTypeGFA\",\n",
    "        \"PropertyGFABuilding(s)\", # => BuildingRatio\n",
    "        # \"PropertyGFAParking\", # => ParkingRatio\n",
    "        # \"SteamUse(kBtu)\",\n",
    "        # \"Electricity(kBtu)\",\n",
    "        \"NaturalGas(kBtu)\",\n",
    "        \"NumberofFloors\",\n",
    "        \"NumberofBuildings\",\n",
    "    ], axis=1, inplace=True)\n",
    "\n",
    "    # DROP NANS EXCEPT FOR ENERGY STAR SCORE FEATURE\n",
    "    # *************************************************************************\n",
    "    feats = [\"ENERGYSTARScore\"]\n",
    "    df_.dropna(subset=df_.columns.difference(feats), inplace=True)\n",
    "\n",
    "    # SORT COLUMNS\n",
    "    # *************************************************************************\n",
    "    df_.sort_index(axis=1, inplace=True)\n",
    "\n",
    "    # SHOW GLOBAL IMPACT\n",
    "    if verbose:\n",
    "        logging.info(\"\"\"\\n***************************************************\n",
    "    üëáüëá   GLOBAL IMPACT  üëáüëá\"\"\")\n",
    "        impact(df, df_)\n",
    "\n",
    "    return df_\n",
    "\n",
    "def X_y_splitter(df, target, random_state=42, valid=False, verbose=False):\n",
    "    \"\"\"\n",
    "    Splits a dataframe in random train, test and even validation samples,\n",
    "    plus same for the target.\n",
    "\n",
    "    Inputs:\n",
    "    ‚Ä¢ df: original dataframe\n",
    "    ‚Ä¢ target: targetted feature (string)\n",
    "    ‚Ä¢ random_state: for randomization fixing (int)\n",
    "    ‚Ä¢ valid: if a validation split is needed (bool, default = False)\n",
    "    ‚Ä¢ verbose: determines whether logs are shown or not (bool, default = False)\n",
    "\n",
    "    Output: 4 or 6 random dataframe samples\n",
    "\n",
    "    Requirements: pandas, sklearn, logging\n",
    "    \"\"\"\n",
    "\n",
    "    X = df.copy()\n",
    "    X.drop(target, axis=1, inplace=True)\n",
    "    y = df[target]\n",
    "\n",
    "    if verbose:\n",
    "        logging.info(f\"{X.shape = }, {y.shape = }\")\n",
    "\n",
    "\n",
    "    if valid:\n",
    "        # train / test : 70-30%\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.3, random_state=random_state)\n",
    "\n",
    "        # validation / test : 50-50% (= 15-15% of total data)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(\n",
    "            X_test, y_test, test_size=0.5, random_state=random_state)\n",
    "\n",
    "        if verbose:\n",
    "            logging.info(f\"{X_train.shape = }, {y_train.shape = }\\n\" +\n",
    "                f\"{X_val.shape = }, {y_val.shape = }\\n\" +\n",
    "                f\"{X_test.shape = }, {y_test.shape = }\")\n",
    "\n",
    "        return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "    # train / test : 80-20%\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "    if verbose:\n",
    "        logging.info(f\"{X_train.shape = }, {y_train.shape = }\\n\" +\n",
    "            f\"{X_test.shape = }, {y_test.shape = }\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def X_splitter(df, random_state=42, valid=False, verbose=False):\n",
    "    \"\"\"\n",
    "    Splits a dataframe in random train, test and even validation samples.\n",
    "\n",
    "    Inputs:\n",
    "    ‚Ä¢ df: original dataframe\n",
    "    ‚Ä¢ random_state: for randomization fixing (int)\n",
    "    ‚Ä¢ valid: if a validation split is needed (bool, default = False)\n",
    "    ‚Ä¢ verbose: determines whether logs are shown or not (bool, default = False)\n",
    "\n",
    "    Output: 2 or 3 random dataframe samples\n",
    "\n",
    "    Requirements: pandas, sklearn, logging\n",
    "    \"\"\"\n",
    "\n",
    "    if valid:\n",
    "        # train / test : 70-30%\n",
    "        X_train, X_test = train_test_split(\n",
    "            df, test_size=0.3, random_state=random_state)\n",
    "\n",
    "        # validation / test : 50-50% (= 15-15% of total data)\n",
    "        X_val, X_test = train_test_split(\n",
    "            X_test, test_size=0.5, random_state=random_state)\n",
    "\n",
    "        if verbose:\n",
    "            logging.info(f\"{df.shape = }, {X_train.shape = }\\n\" +\n",
    "                f\"{X_val.shape = }, {X_test.shape = }\")\n",
    "\n",
    "        return X_train, X_val, X_test\n",
    "\n",
    "    # train / test : 80-20%\n",
    "    X_train, X_test = train_test_split(\n",
    "        df, test_size=0.2, random_state=random_state)\n",
    "\n",
    "    if verbose:\n",
    "        logging.info(f\"{df.shape = }, {X_train.shape = }, {X_test.shape = }\")\n",
    "\n",
    "    return X_train, X_test\n",
    "\n",
    "def y_splitter(df, target, verbose=False):\n",
    "    \"\"\"\n",
    "    Separates a dataframe from its target.\n",
    "\n",
    "    Inputs:\n",
    "    ‚Ä¢ df: original dataframe\n",
    "    ‚Ä¢ target: targetted feature (string)\n",
    "    ‚Ä¢ verbose: determines whether logs are shown or not (bool, default = False)\n",
    "\n",
    "    Output: 1 dataframe and 1 series (target)\n",
    "\n",
    "    Requirements: pandas, sklearn, logging\n",
    "    \"\"\"\n",
    "\n",
    "    X = df.copy()\n",
    "    X.drop(target, axis=1, inplace=True)\n",
    "    y = df[target]\n",
    "\n",
    "    if verbose:\n",
    "        logging.info(f\"{X.shape = }, {y.shape = }\")\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def compare_df(y_train, y_test, name):\n",
    "    \"\"\"\n",
    "    Compare quickly 2 target Series splits.\n",
    "\n",
    "    Input: 2 dataframes or series (\"train\" and \"test\")\n",
    "    Output: comparison dataframe\n",
    "\n",
    "    Requirements: numpy, pandas\n",
    "    \"\"\"\n",
    "\n",
    "    compere = pd.DataFrame(columns=[\"pop\", \"min\", \"max\", \"mean\", \"med\", \"std\"])\n",
    "    \n",
    "    compere.loc[\"y_train_\" + str(name)] = [y_train.shape[0], y_train.min(),\n",
    "        y_train.max(), y_train.mean(), y_train.median(), y_train.std()]\n",
    "    \n",
    "    compere.loc[\"y_test_\" + str(name)] = [y_test.shape[0], y_test.min(),\n",
    "        y_test.max(), y_test.mean(), y_test.median(), y_test.std()]\n",
    "    \n",
    "    return compere\n",
    "\n",
    "def process_all(df, non_res_min_usage, random_state, target, scores_df,\n",
    "    verbose=False):\n",
    "    \"\"\"\n",
    "    All-in-one processing, for parameters comparisons.\n",
    "\n",
    "    scores_df = pd.DataFrame(columns=[\"rdm_st\", \"metric\", \"LinReg\", \"SVR\",\n",
    "        \"RdmForestReg\", \"GradBoostReg\", \"MEAN\", \"MEDIAN\"])\n",
    "    \"\"\"\n",
    "\n",
    "    df_ = df.copy()\n",
    "\n",
    "    # PARAMS\n",
    "    # *************************************************************************\n",
    "    non_res_min_usage = non_res_min_usage\n",
    "    random_state = random_state\n",
    "    target = target\n",
    "    classif_cols = [\"Neighborhood\"]\n",
    "\n",
    "    # CLEAN\n",
    "    # *************************************************************************\n",
    "    df_ = data_cleaner(df_, non_res_min_usage)\n",
    "\n",
    "    # REMAINING PARAMS (must be done after cleaning)\n",
    "    # *************************************************************************\n",
    "    num_cols = df_.drop(classif_cols, axis=1).columns.to_list()\n",
    "    num_cols.remove(target)\n",
    "\n",
    "    # PIPELINES DEFINITIONS\n",
    "    # *************************************************************************\n",
    "    col_transf = ColumnTransformer(\n",
    "        [\n",
    "            ('one_hot', OneHotEncoder(handle_unknown='ignore'), classif_cols),\n",
    "            ('min_max_scaler', MinMaxScaler(), num_cols),\n",
    "        ],\n",
    "        remainder = 'passthrough',\n",
    "        verbose_feature_names_out=False\n",
    "    )\n",
    "\n",
    "    imputer = Pipeline(\n",
    "        [\n",
    "            ('knn_imputer', KNNImputer(n_neighbors=5)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    preprocessor = Pipeline(\n",
    "        [\n",
    "            (\"col_transf\", col_transf),\n",
    "            ('knn_imputer', KNNImputer(n_neighbors=5)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # SPLIT\n",
    "    # *************************************************************************\n",
    "    X_train, X_test, y_train, y_test = X_y_splitter(\n",
    "        df_, target, random_state)\n",
    "    \n",
    "    # -> to dataframe\n",
    "    X_train = pd.DataFrame(preprocessor.fit_transform(X_train),\n",
    "            columns=preprocessor[0:].get_feature_names_out())\n",
    "    X_test = pd.DataFrame(preprocessor.fit_transform(X_test),\n",
    "            columns=preprocessor[0:].get_feature_names_out())\n",
    "    \n",
    "    # for further comparison\n",
    "    y_split = compare_df(y_train, y_test, random_state)\n",
    "\n",
    "    # ESTIMATORS\n",
    "    # *************************************************************************\n",
    "    models_names = [\"Dummy\", \"LinReg\", \"SVR\", \"RdmForestReg\", \"GradBoostReg\"]\n",
    "    \n",
    "    # pipelines\n",
    "    pipelines = [\n",
    "        Pipeline([('Dummy', DummyRegressor(strategy=\"mean\"))]),\n",
    "        Pipeline([('LinReg', LinearRegression())]),\n",
    "        Pipeline([('SVR', svm.SVR(kernel='linear'))]),\n",
    "        Pipeline([('RdmForestReg', RandomForestRegressor())]),\n",
    "        Pipeline([('GradBoostReg', GradientBoostingRegressor())]),\n",
    "    ]\n",
    "\n",
    "    # scores (DF preparation)\n",
    "    row_name = \"rdm_st_\" + str(random_state)\n",
    "    scores_df.loc[row_name + \"_r2\"] = \"-\"\n",
    "    scores_df.loc[row_name + \"_mae\"] = \"-\"\n",
    "    scores_df.loc[row_name + \"_rmse\"] = \"-\"\n",
    "    scores_df.loc[row_name + \"_ttime\"] = \"-\"\n",
    "\n",
    "    scores_df[\"rdm_st\"][row_name + \"_r2\"] = random_state\n",
    "    scores_df[\"metric\"][row_name + \"_r2\"] = \"r2\"\n",
    "\n",
    "    scores_df[\"rdm_st\"][row_name + \"_mae\"] = random_state\n",
    "    scores_df[\"metric\"][row_name + \"_mae\"] = \"mae\"\n",
    "\n",
    "    scores_df[\"rdm_st\"][row_name + \"_rmse\"] = random_state\n",
    "    scores_df[\"metric\"][row_name + \"_rmse\"] = \"rmse\"\n",
    "    \n",
    "    scores_df[\"rdm_st\"][row_name + \"_ttime\"] = random_state\n",
    "    scores_df[\"metric\"][row_name + \"_ttime\"] = \"seconds\"\n",
    "\n",
    "    # loop over estimators\n",
    "    for p, name in zip(pipelines, models_names):\n",
    "        start = time.time()\n",
    "        p.fit(X_train, y_train)\n",
    "        end = time.time()\n",
    "        fit_time = end - start\n",
    "\n",
    "        r2 = round(r2_score(y_test, p.predict(X_test)), 3)\n",
    "        mae = round(mean_absolute_error(y_test, p.predict(X_test)), 3)\n",
    "        rmse = round(mean_squared_error(y_test, p.predict(X_test),\n",
    "            squared = False), 3)\n",
    "\n",
    "        # save scores in DF\n",
    "        if name != \"Dummy\":\n",
    "            scores_df[name][row_name + \"_r2\"] = r2\n",
    "            scores_df[name][row_name + \"_mae\"] = mae\n",
    "            scores_df[name][row_name + \"_rmse\"] = rmse\n",
    "            scores_df[name][row_name + \"_ttime\"] = fit_time\n",
    "\n",
    "    # means and medians for estimators\n",
    "    scores_df[\"MEAN\"][row_name + \"_r2\"] = round(\n",
    "        scores_df.loc[row_name + \"_r2\"][2:6].mean(), 3)\n",
    "    scores_df[\"MEAN\"][row_name + \"_mae\"] = round(\n",
    "        scores_df.loc[row_name + \"_mae\"][2:6].mean(), 3)\n",
    "    scores_df[\"MEAN\"][row_name + \"_rmse\"] = round(\n",
    "        scores_df.loc[row_name + \"_rmse\"][2:6].mean(), 3)\n",
    "\n",
    "    scores_df[\"MEDIAN\"][row_name + \"_r2\"] = round(\n",
    "        scores_df.loc[row_name + \"_r2\"][2:6].median(), 3)\n",
    "    scores_df[\"MEDIAN\"][row_name + \"_mae\"] = round(\n",
    "        scores_df.loc[row_name + \"_mae\"][2:6].median(), 3)\n",
    "    scores_df[\"MEDIAN\"][row_name + \"_rmse\"] = round(\n",
    "        scores_df.loc[row_name + \"_rmse\"][2:6].median(), 3)\n",
    "\n",
    "    if verbose:\n",
    "        display(y_split)\n",
    "        display(scores_df)\n",
    "\n",
    "    return y_split, scores_df\n",
    "\n",
    "def display_r2(action):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    print(action[0])\n",
    "\n",
    "    scores = action[2]\n",
    "\n",
    "    # r2 results\n",
    "    r2_all = scores.loc[scores[\"metric\"] == \"r2\"]\n",
    "    # global mean score for a same random state\n",
    "    r2_all.loc[\"TOTAL\"] = [\n",
    "        \"-\",\n",
    "        \"-\",\n",
    "        round(r2_all[\"LinReg\"].mean(), 3),\n",
    "        round(r2_all[\"SVR\"].mean(), 3),\n",
    "        round(r2_all[\"RdmForestReg\"].mean(), 3),\n",
    "        round(r2_all[\"GradBoostReg\"].mean(), 3),\n",
    "        round(r2_all[\"MEAN\"].mean(), 3),\n",
    "        round(r2_all[\"MEDIAN\"].mean(), 3),\n",
    "    ]\n",
    "    display(r2_all)\n",
    "\n",
    "    # graphic figure\n",
    "    df_ = r2_all.drop(\"TOTAL\", axis=0)\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=df_[\"rdm_st\"], y=df_[\"LinReg\"],\n",
    "        mode='lines+markers', name='LinReg'))\n",
    "    fig.add_trace(go.Scatter(x=df_[\"rdm_st\"], y=df_[\"SVR\"],\n",
    "        mode='lines+markers', name='SVR'))\n",
    "    fig.add_trace(go.Scatter(x=df_[\"rdm_st\"], y=df_[\"RdmForestReg\"],\n",
    "        mode='lines+markers', name='RdmForestReg'))\n",
    "    fig.add_trace(go.Scatter(x=df_[\"rdm_st\"], y=df_[\"GradBoostReg\"],\n",
    "        mode='lines+markers', name='GradBoostReg'))\n",
    "    fig.add_trace(go.Scatter(x=df_[\"rdm_st\"], y=df_[\"MEAN\"],\n",
    "        mode='lines+markers', name='MEAN'))\n",
    "    fig.show()\n",
    "\n",
    "    return\n",
    "\n",
    "def display_all_r2(scores_list):\n",
    "    \"\"\"\n",
    "    Displays a plot of all r2 scores for step by step analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    columns = ['LinReg', 'SVR', 'RdmForestReg', 'GradBoostReg', \"mean\",\n",
    "        \"median\"]\n",
    "    full_r2 = pd.DataFrame(columns=columns)\n",
    "\n",
    "    for f in scores_list:\n",
    "        # get variable name\n",
    "        name = f[0]\n",
    "        \n",
    "        _ = f[3].loc[f[3][\"metric\"] == \"r2\"]\n",
    "        linreg = round(_[\"LinReg\"].mean(), 3)\n",
    "        svr = round(_[\"SVR\"].mean(), 3)\n",
    "        rdmforest = round(_[\"RdmForestReg\"].mean(), 3)\n",
    "        gradboost = round(_[\"GradBoostReg\"].mean(), 3)\n",
    "\n",
    "        full_r2.loc[name] = [\n",
    "            linreg,\n",
    "            svr,\n",
    "            rdmforest,\n",
    "            gradboost,\n",
    "            round(np.mean([linreg, svr, rdmforest, gradboost]), 3),\n",
    "            round(np.median([linreg, svr, rdmforest, gradboost]), 3),\n",
    "        ]\n",
    "\n",
    "        # mask if too high / low\n",
    "        full_r2.mask(full_r2 > 3, 3, inplace=True)\n",
    "        full_r2.mask(full_r2 < -3, -3, inplace=True)\n",
    " \n",
    "    # graphic figure\n",
    "    layout = go.Layout(yaxis=dict(range=[-0.5, 1]))\n",
    "    fig = go.Figure(layout=layout)\n",
    "    fig.add_trace(go.Scatter(x=full_r2.index, y=full_r2[\"LinReg\"],\n",
    "        mode='lines+markers', name='LinReg'))\n",
    "    fig.add_trace(go.Scatter(x=full_r2.index, y=full_r2[\"SVR\"],\n",
    "        mode='lines+markers', name='SVR'))\n",
    "    fig.add_trace(go.Scatter(x=full_r2.index, y=full_r2[\"RdmForestReg\"],\n",
    "        mode='lines+markers', name='RdmForestReg'))\n",
    "    fig.add_trace(go.Scatter(x=full_r2.index, y=full_r2[\"GradBoostReg\"],\n",
    "        mode='lines+markers', name='GradBoostReg'))\n",
    "    fig.add_trace(go.Scatter(x=full_r2.index, y=full_r2[\"mean\"],\n",
    "        mode='lines+markers', name='mean'))\n",
    "    fig.add_trace(go.Scatter(x=full_r2.index, y=full_r2[\"median\"],\n",
    "        mode='lines+markers', name='median'))\n",
    "    fig.show()\n",
    "\n",
    "    print(\"\"\"save_actions = BASE: drop duplicates (0), keep compliants only, clean neighborhood, drop useless feats, drop nans except ENERGYSTARScore, sort columns\n",
    "save_actions_2    = BASE + filter GHGEmissionsIntensity, NumberofBuildings, NumberofFloors, PropertyGFATotal (22)\n",
    "save_actions_3    = ........ + create BuildingRatio feature\n",
    "save_actions_4    = ............ + drop PropertyGFABuilding(s) feature\n",
    "save_actions_5    = ................ + filter BuildingRatio (19)\n",
    "save_actions_6    = .................|.. + create ParkingRatio feature\n",
    "save_actions_6_1  = .................|...... + drop PropertyGFAParking feature\n",
    "save_actions_6_2  = .................|.......... + filter ParkingRatio (8)\n",
    "save_actions_7    = ................ + create AreaPerFloor(sf) and AreaPerBldg(sf) features\n",
    "save_actions_7_1  = .................... + drop NumberofFloors and NumberofBuildings features\n",
    "save_actions_7_2  = ........................ + filter AreaPerFloor(sf) (1)\n",
    "save_actions_8    = ............................ + create SteamUse_I(kBtu/sf), Electricity_I(kBtu/sf) and NaturalGas_I(kBtu/sf) features\n",
    "save_actions_8_1  = .............................|.. + drop SteamUse(kBtu), Electricity(kBtu) and NaturalGas(kBtu) features\n",
    "save_actions_8_2  = .............................|...... + filter SteamUse_I(kBtu/sf) (6), Electricity_I(kBtu/sf) (6)\n",
    "save_actions_9    = .............................|.......... + create NonResidentialRatio feature\n",
    "save_actions_9_1  = .............................|.............. + filter NonResidentialRatio >= min_nr_pct (often > 1000)\n",
    "save_actions_10   = .............................|.................. + create ParkingRatio, drop PropertyGFAParking, filter ParkingRatio (8)\n",
    "save_actions_11   = ............................ + create NonResidentialRatio + filter >= min_nr_pct (often > 1000)\n",
    "save_actions_11_1 = .............................|.. + create ParkingRatio, drop PropertyGFAParking feature, filter ParkingRatio (8)\n",
    "save_actions_12   = ............................ + STEAMUSE: create SteamUse_I(kBtu/sf), drop SteamUse(kBtu), filter SteamUse_I(kBtu/sf) (6)\n",
    "save_actions_13   = ............................ + ELECTRICITY: create Electricity_I(kBtu/sf), drop Electricity(kBtu), filter Electricity_I(kBtu/sf) (6)\n",
    "save_actions_14   = ............................ + NATURALGAS: create NaturalGas_I(kBtu/sf), drop NaturalGas(kBtu)\n",
    "\"\"\")\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Estimateurs : comparaison et recherche de fuite](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 16s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "non_res_min_usage = 0.0001\n",
    "target = \"GHGEmissionsIntensity\"\n",
    "splits = pd.DataFrame()\n",
    "scores = pd.DataFrame(columns=[\"rdm_st\", \"metric\", \"LinReg\", \"SVR\",\n",
    "    \"RdmForestReg\", \"GradBoostReg\", \"MEAN\", \"MEDIAN\"])\n",
    "\n",
    "random_state = range(10)\n",
    "\n",
    "for rs in random_state:\n",
    "    y_split, _ = process_all(data_raw, non_res_min_usage, rs, target,\n",
    "        scores, verbose=False)\n",
    "    splits = pd.concat([splits, y_split])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Tableau comparatif](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"\"\"ACTIONS:\n",
    "- drop duplicates\n",
    "- keep compliants only\n",
    "- clean neighborhood\n",
    "- drop useless feats\n",
    "\n",
    "PLUS\n",
    "- create `BuildingRatio` feature\n",
    "- drop `PropertyGFABuilding(s)` feature\n",
    "\n",
    "- create `AreaPerFloor(sf)` feature\n",
    "- create `AreaPerBldg(sf)` feature\n",
    "- drop `NumberofFloors` feature  \n",
    "- drop `NumberofBuildings` feature\n",
    "- filter `AreaPerFloor(sf)` <= 0.004 (1 individual)\n",
    "\n",
    "- create `NaturalGas_I(kBtu/sf)` feature\n",
    "- drop `NaturalGas(kBtu)` feature\n",
    "\n",
    "- filter `GHGEmissionsIntensity` <= 20 (2 individuals)\n",
    "- filter `NumberofBuildings` <= 20 (3 individuals)\n",
    "- filter `NumberofFloors` <= 40 (16 individuals)\n",
    "- filter `PropertyGFATotal` <= 2000000 (1 individual)\n",
    "\n",
    "AND\n",
    "- drop last useless feats\n",
    "- drop nans except ENERGYSTARScore\n",
    "- sort columns\n",
    "\"\"\"\n",
    "\n",
    "# save_actions_14 = [txt, splits, scores]\n",
    "# %store save_actions_14"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[M√©thode pas √† pas](#toc0_)\n",
    "\n",
    "Application des divers traitements et analyse pas √† pas des r√©sultats pour d√©tecter la fuite de donn√©es √©ventuelle."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement de base\n",
    "\n",
    "(r√©sultats dans variable `save_actions`)\n",
    "\n",
    "BASIC ACTIONS:\n",
    "- drop duplicates\n",
    "- keep compliants only\n",
    "- clean neighborhood\n",
    "- drop useless feats\n",
    "\n",
    "AND\n",
    "- drop last useless feats\n",
    "- drop nans except ENERGYSTARScore\n",
    "- sort columns\n",
    "\n",
    "**‚û°Ô∏è -21395404395282247680.0**\n",
    "\n",
    "mais si on enl√®ve la r√©gression lin√©aire :  \n",
    "**‚û°Ô∏è -0.674**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r save_actions\n",
    "# display_r2(save_actions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save_actions_2\n",
    "\n",
    "BASE +\n",
    "- filter `GHGEmissionsIntensity` <= 20 (2 individuals)\n",
    "- filter `NumberofBuildings` <= 20 (3 individuals)\n",
    "- filter `NumberofFloors` <= 40 (16 individuals)\n",
    "- filter `PropertyGFATotal` <= 2000000 (1 individual)\n",
    "\n",
    "**‚û°Ô∏è -23870982611243671552.0**\n",
    "\n",
    "mais si on enl√®ve la r√©gression lin√©aire :  \n",
    "**‚û°Ô∏è 0.446**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r save_actions_2\n",
    "# display_r2(save_actions_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save_actions_3\n",
    "\n",
    "BASE +  \n",
    "save_actions_2  \n",
    "- filter `GHGEmissionsIntensity` <= 20 (2 individuals)\n",
    "- filter `NumberofBuildings` <= 20 (3 individuals)\n",
    "- filter `NumberofFloors` <= 40 (16 individuals)\n",
    "- filter `PropertyGFATotal` <= 2000000 (1 individual)\n",
    "\n",
    "\\+ create `BuildingRatio` feature\n",
    "\n",
    "**‚û°Ô∏è -64882775773597270016.0**\n",
    "\n",
    "mais si on enl√®ve la r√©gression lin√©aire :  \n",
    "**‚û°Ô∏è 0.443**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r save_actions_3\n",
    "# display_r2(save_actions_3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save_actions_4\n",
    "\n",
    "BASE +  \n",
    "save_actions_3\n",
    "- filter `GHGEmissionsIntensity` <= 20 (2 individuals)\n",
    "- filter `NumberofBuildings` <= 20 (3 individuals)\n",
    "- filter `NumberofFloors` <= 40 (16 individuals)\n",
    "- filter `PropertyGFATotal` <= 2000000 (1 individual)\n",
    "- create `BuildingRatio` feature\n",
    "\n",
    "\\+ drop `PropertyGFABuilding(s)` feature\n",
    "\n",
    "**‚û°Ô∏è 0.361**\n",
    "\n",
    "‚úÖ r√®gle le souci de r√©gression lin√©aire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r save_actions_4\n",
    "# display_r2(save_actions_4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save_actions_5\n",
    "\n",
    "BASE +  \n",
    "save_actions_4\n",
    "- filter `GHGEmissionsIntensity` <= 20 (2 individuals)\n",
    "- filter `NumberofBuildings` <= 20 (3 individuals)\n",
    "- filter `NumberofFloors` <= 40 (16 individuals)\n",
    "- filter `PropertyGFATotal` <= 2000000 (1 individual)\n",
    "- create `BuildingRatio` feature\n",
    "- drop `PropertyGFABuilding(s)` feature\n",
    "\n",
    "\\+ filter `BuildingRatio` >= 0.4 (19 individuals)\n",
    "\n",
    "**‚û°Ô∏è 0.078**\n",
    "\n",
    "‚ùå chute mod√®le : abandon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r save_actions_5\n",
    "# display_r2(save_actions_5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save_actions_6\n",
    "\n",
    "BASE +  \n",
    "save_actions_4\n",
    "- filter `GHGEmissionsIntensity` <= 20 (2 individuals)\n",
    "- filter `NumberofBuildings` <= 20 (3 individuals)\n",
    "- filter `NumberofFloors` <= 40 (16 individuals)\n",
    "- filter `PropertyGFATotal` <= 2000000 (1 individual)\n",
    "- create `BuildingRatio` feature\n",
    "- drop `PropertyGFABuilding(s)` feature\n",
    "\n",
    "\\+ create `ParkingRatio` feature\n",
    "\n",
    "**‚û°Ô∏è 0.1**\n",
    "\n",
    "‚ùå chute mod√®le ‚Üí approfondissement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r save_actions_6\n",
    "# display_r2(save_actions_6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save_actions_6.1\n",
    "\n",
    "BASE +  \n",
    "save_actions_6\n",
    "- filter `GHGEmissionsIntensity` <= 20 (2 individuals)\n",
    "- filter `NumberofBuildings` <= 20 (3 individuals)\n",
    "- filter `NumberofFloors` <= 40 (16 individuals)\n",
    "- filter `PropertyGFATotal` <= 2000000 (1 individual)\n",
    "- create `BuildingRatio` feature\n",
    "- drop `PropertyGFABuilding(s)` feature\n",
    "- create `ParkingRatio` feature\n",
    "\n",
    "\\+ drop `PropertyGFAParking` feature\n",
    "\n",
    "**‚û°Ô∏è 0.096**\n",
    "\n",
    "‚ùå toujours bof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r save_actions_6_1\n",
    "# display_r2(save_actions_6_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save_actions_6.2\n",
    "\n",
    "BASE +  \n",
    "save_actions_6.1\n",
    "- filter `GHGEmissionsIntensity` <= 20 (2 individuals)\n",
    "- filter `NumberofBuildings` <= 20 (3 individuals)\n",
    "- filter `NumberofFloors` <= 40 (16 individuals)\n",
    "- filter `PropertyGFATotal` <= 2000000 (1 individual)\n",
    "- create `BuildingRatio` feature\n",
    "- drop `PropertyGFABuilding(s)` feature\n",
    "- create `ParkingRatio` feature\n",
    "- drop `PropertyGFAParking` feature\n",
    "\n",
    "\\+ filter `ParkingRatio` <= 0.8 (8 individuals)\n",
    "\n",
    "**‚û°Ô∏è -0.092**\n",
    "\n",
    "‚ùå encore chut√© : abandon de la branche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r save_actions_6_2\n",
    "# display_r2(save_actions_6_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save_actions_7\n",
    "\n",
    "BASE +  \n",
    "save_actions_4\n",
    "- filter `GHGEmissionsIntensity` <= 20 (2 individuals)\n",
    "- filter `NumberofBuildings` <= 20 (3 individuals)\n",
    "- filter `NumberofFloors` <= 40 (16 individuals)\n",
    "- filter `PropertyGFATotal` <= 2000000 (1 individual)\n",
    "- create `BuildingRatio` feature\n",
    "- drop `PropertyGFABuilding(s)` feature\n",
    "\n",
    "\\+ create `AreaPerFloor(sf)` feature  \n",
    "\\+ create `AreaPerBldg(sf)` feature\n",
    "\n",
    "**‚û°Ô∏è 0.31**\n",
    "\n",
    "‚Üò un peu baiss√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r save_actions_7\n",
    "# display_r2(save_actions_7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save_actions_7_1\n",
    "\n",
    "BASE +  \n",
    "save_actions_7\n",
    "- filter `GHGEmissionsIntensity` <= 20 (2 individuals)\n",
    "- filter `NumberofBuildings` <= 20 (3 individuals)\n",
    "- filter `NumberofFloors` <= 40 (16 individuals)\n",
    "- filter `PropertyGFATotal` <= 2000000 (1 individual)\n",
    "- create `BuildingRatio` feature\n",
    "- drop `PropertyGFABuilding(s)` feature\n",
    "- create `AreaPerFloor(sf)` feature  \n",
    "- create `AreaPerBldg(sf)` feature\n",
    "\n",
    "\\+ drop `NumberofFloors` feature  \n",
    "\\+ drop `NumberofBuildings` feature\n",
    "\n",
    "**‚û°Ô∏è 0.327**\n",
    "\n",
    "‚ÜóÔ∏è l√©g√®re hausse du r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r save_actions_7_1\n",
    "# display_r2(save_actions_7_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save_actions_7_2\n",
    "\n",
    "BASE +  \n",
    "save_actions_7_1\n",
    "- filter `GHGEmissionsIntensity` <= 20 (2 individuals)\n",
    "- filter `NumberofBuildings` <= 20 (3 individuals)\n",
    "- filter `NumberofFloors` <= 40 (16 individuals)\n",
    "- filter `PropertyGFATotal` <= 2000000 (1 individual)\n",
    "- create `BuildingRatio` feature\n",
    "- drop `PropertyGFABuilding(s)` feature\n",
    "- create `AreaPerFloor(sf)` feature  \n",
    "- create `AreaPerBldg(sf)` feature\n",
    "- drop `NumberofFloors` feature\n",
    "- drop `NumberofBuildings` feature\n",
    "\n",
    "\\+ filter `AreaPerFloor(sf)` <= 0.004 (1 individual)\n",
    "\n",
    "**‚û°Ô∏è 0.328**\n",
    "\n",
    "‚âà avant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r save_actions_7_2\n",
    "# display_r2(save_actions_7_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save_actions_8\n",
    "\n",
    "BASE +  \n",
    "save_actions_7_2\n",
    "- filter `GHGEmissionsIntensity` <= 20 (2 individuals)\n",
    "- filter `NumberofBuildings` <= 20 (3 individuals)\n",
    "- filter `NumberofFloors` <= 40 (16 individuals)\n",
    "- filter `PropertyGFATotal` <= 2000000 (1 individual)\n",
    "- create `BuildingRatio` feature\n",
    "- drop `PropertyGFABuilding(s)` feature\n",
    "- create `AreaPerFloor(sf)` feature  \n",
    "- create `AreaPerBldg(sf)` feature\n",
    "- drop `NumberofFloors` feature\n",
    "- drop `NumberofBuildings` feature\n",
    "- filter `AreaPerFloor(sf)` <= 0.004 (1 individual)\n",
    "\n",
    "\\+ create `SteamUse_I(kBtu/sf)` feature  \n",
    "\\+ create `Electricity_I(kBtu/sf)` feature  \n",
    "\\+ create `NaturalGas_I(kBtu/sf)` feature\n",
    "\n",
    "**‚û°Ô∏è 0.603**\n",
    "\n",
    "‚Üó‚Üó belle augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r save_actions_8\n",
    "# display_r2(save_actions_8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save_actions_8_1\n",
    "\n",
    "BASE +  \n",
    "save_actions_8\n",
    "- filter `GHGEmissionsIntensity` <= 20 (2 individuals)\n",
    "- filter `NumberofBuildings` <= 20 (3 individuals)\n",
    "- filter `NumberofFloors` <= 40 (16 individuals)\n",
    "- filter `PropertyGFATotal` <= 2000000 (1 individual)\n",
    "- create `BuildingRatio` feature\n",
    "- drop `PropertyGFABuilding(s)` feature\n",
    "- create `AreaPerFloor(sf)` feature  \n",
    "- create `AreaPerBldg(sf)` feature\n",
    "- drop `NumberofFloors` feature\n",
    "- drop `NumberofBuildings` feature\n",
    "- filter `AreaPerFloor(sf)` <= 0.004 (1 individual)\n",
    "- create `SteamUse_I(kBtu/sf)` feature\n",
    "- create `Electricity_I(kBtu/sf)` feature\n",
    "- create `NaturalGas_I(kBtu/sf)` feature\n",
    "\n",
    "\\+ drop `SteamUse(kBtu)` feature  \n",
    "\\+ drop `Electricity(kBtu)` feature  \n",
    "\\+ drop `NaturalGas(kBtu)` feature  \n",
    "\n",
    "**‚û°Ô∏è 0.603**\n",
    "\n",
    "== kif-kif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r save_actions_8_1\n",
    "# display_r2(save_actions_8_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save_actions_8_2\n",
    "\n",
    "BASE +  \n",
    "save_actions_8_1\n",
    "- filter `GHGEmissionsIntensity` <= 20 (2 individuals)\n",
    "- filter `NumberofBuildings` <= 20 (3 individuals)\n",
    "- filter `NumberofFloors` <= 40 (16 individuals)\n",
    "- filter `PropertyGFATotal` <= 2000000 (1 individual)\n",
    "- create `BuildingRatio` feature\n",
    "- drop `PropertyGFABuilding(s)` feature\n",
    "- create `AreaPerFloor(sf)` feature  \n",
    "- create `AreaPerBldg(sf)` feature\n",
    "- drop `NumberofFloors` feature\n",
    "- drop `NumberofBuildings` feature\n",
    "- filter `AreaPerFloor(sf)` <= 0.004 (1 individual)\n",
    "- create `SteamUse_I(kBtu/sf)` feature\n",
    "- create `Electricity_I(kBtu/sf)` feature\n",
    "- create `NaturalGas_I(kBtu/sf)` feature\n",
    "- drop `SteamUse(kBtu)` feature\n",
    "- drop `Electricity(kBtu)` feature\n",
    "- drop `NaturalGas(kBtu)` feature\n",
    "\n",
    "\\+ filter `SteamUse_I(kBtu/sf)` <= 100 (6 individuals)  \n",
    "\\+ filter `Electricity_I(kBtu/sf)` <= 350 (6 individuals)\n",
    "\n",
    "**‚û°Ô∏è 0.862**\n",
    "\n",
    "‚ùì‚ùì‚ùì‚ùì tr√®s bien ou fuite ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r save_actions_8_2\n",
    "# display_r2(save_actions_8_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save_actions_9\n",
    "\n",
    "BASE +  \n",
    "save_actions_8_2\n",
    "- filter `GHGEmissionsIntensity` <= 20 (2 individuals)\n",
    "- filter `NumberofBuildings` <= 20 (3 individuals)\n",
    "- filter `NumberofFloors` <= 40 (16 individuals)\n",
    "- filter `PropertyGFATotal` <= 2000000 (1 individual)\n",
    "- create `BuildingRatio` feature\n",
    "- drop `PropertyGFABuilding(s)` feature\n",
    "- create `AreaPerFloor(sf)` feature  \n",
    "- create `AreaPerBldg(sf)` feature\n",
    "- drop `NumberofFloors` feature\n",
    "- drop `NumberofBuildings` feature\n",
    "- filter `AreaPerFloor(sf)` <= 0.004 (1 individual)\n",
    "- create `SteamUse_I(kBtu/sf)` feature\n",
    "- create `Electricity_I(kBtu/sf)` feature\n",
    "- create `NaturalGas_I(kBtu/sf)` feature\n",
    "- drop `SteamUse(kBtu)` feature\n",
    "- drop `Electricity(kBtu)` feature\n",
    "- drop `NaturalGas(kBtu)` feature\n",
    "- filter `SteamUse_I(kBtu/sf)` <= 100 (6 individuals)  \n",
    "- filter `Electricity_I(kBtu/sf)` <= 350 (6 individuals)\n",
    "\n",
    "\\+ create `NonResidentialRatio` feature\n",
    "\n",
    "**‚û°Ô∏è 0.863**\n",
    "\n",
    "== idem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r save_actions_9\n",
    "# display_r2(save_actions_9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save_actions_9_1\n",
    "\n",
    "BASE +  \n",
    "save_actions_9\n",
    "- filter `GHGEmissionsIntensity` <= 20 (2 individuals)\n",
    "- filter `NumberofBuildings` <= 20 (3 individuals)\n",
    "- filter `NumberofFloors` <= 40 (16 individuals)\n",
    "- filter `PropertyGFATotal` <= 2000000 (1 individual)\n",
    "- create `BuildingRatio` feature\n",
    "- drop `PropertyGFABuilding(s)` feature\n",
    "- create `AreaPerFloor(sf)` feature  \n",
    "- create `AreaPerBldg(sf)` feature\n",
    "- drop `NumberofFloors` feature\n",
    "- drop `NumberofBuildings` feature\n",
    "- filter `AreaPerFloor(sf)` <= 0.004 (1 individual)\n",
    "- create `SteamUse_I(kBtu/sf)` feature\n",
    "- create `Electricity_I(kBtu/sf)` feature\n",
    "- create `NaturalGas_I(kBtu/sf)` feature\n",
    "- drop `SteamUse(kBtu)` feature\n",
    "- drop `Electricity(kBtu)` feature\n",
    "- drop `NaturalGas(kBtu)` feature\n",
    "- filter `SteamUse_I(kBtu/sf)` <= 100 (6 individuals)  \n",
    "- filter `Electricity_I(kBtu/sf)` <= 350 (6 individuals)\n",
    "- create `NonResidentialRatio` feature\n",
    "\n",
    "\\+ filter `NonResidentialRatio` >= min_nr_pct (often > 1000 individuals)\n",
    "\n",
    "**‚û°Ô∏è 0.934**\n",
    "\n",
    "‚ùì‚ùì‚ùì‚ùì idem : fuite ou bien ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r save_actions_9_1\n",
    "# display_r2(save_actions_9_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save_actions_10\n",
    "\n",
    "BASE +  \n",
    "save_actions_9_1\n",
    "- filter `GHGEmissionsIntensity` <= 20 (2 individuals)\n",
    "- filter `NumberofBuildings` <= 20 (3 individuals)\n",
    "- filter `NumberofFloors` <= 40 (16 individuals)\n",
    "- filter `PropertyGFATotal` <= 2000000 (1 individual)\n",
    "- create `BuildingRatio` feature\n",
    "- drop `PropertyGFABuilding(s)` feature\n",
    "- create `AreaPerFloor(sf)` feature  \n",
    "- create `AreaPerBldg(sf)` feature\n",
    "- drop `NumberofFloors` feature\n",
    "- drop `NumberofBuildings` feature\n",
    "- filter `AreaPerFloor(sf)` <= 0.004 (1 individual)\n",
    "- create `SteamUse_I(kBtu/sf)` feature\n",
    "- create `Electricity_I(kBtu/sf)` feature\n",
    "- create `NaturalGas_I(kBtu/sf)` feature\n",
    "- drop `SteamUse(kBtu)` feature\n",
    "- drop `Electricity(kBtu)` feature\n",
    "- drop `NaturalGas(kBtu)` feature\n",
    "- filter `SteamUse_I(kBtu/sf)` <= 100 (6 individuals)  \n",
    "- filter `Electricity_I(kBtu/sf)` <= 350 (6 individuals)\n",
    "- create `NonResidentialRatio` feature\n",
    "- filter `NonResidentialRatio` >= min_nr_pct (often > 1000 individuals)\n",
    "\n",
    "\\+ create `ParkingRatio` feature  \n",
    "\\+ drop `PropertyGFAParking` feature  \n",
    "\\+ filter `ParkingRatio` <= 0.8 (8 individuals)\n",
    "\n",
    "**‚û°Ô∏è 0.961**\n",
    "\n",
    "‚ÜóÔ∏è cette fois, l√©g√®re am√©lioration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r save_actions_10\n",
    "# display_r2(save_actions_10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save_actions_11\n",
    "\n",
    "BASE +  \n",
    "save_actions_7_2\n",
    "- filter `GHGEmissionsIntensity` <= 20 (2 individuals)\n",
    "- filter `NumberofBuildings` <= 20 (3 individuals)\n",
    "- filter `NumberofFloors` <= 40 (16 individuals)\n",
    "- filter `PropertyGFATotal` <= 2000000 (1 individual)\n",
    "- create `BuildingRatio` feature\n",
    "- drop `PropertyGFABuilding(s)` feature\n",
    "- create `AreaPerFloor(sf)` feature  \n",
    "- create `AreaPerBldg(sf)` feature\n",
    "- drop `NumberofFloors` feature\n",
    "- drop `NumberofBuildings` feature\n",
    "- filter `AreaPerFloor(sf)` <= 0.004 (1 individual)\n",
    "\n",
    "\\+ create `NonResidentialRatio` feature  \n",
    "\\+ filter `NonResidentialRatio` >= min_nr_pct (often > 1000 individuals)\n",
    "\n",
    "**‚û°Ô∏è 0.007**\n",
    "\n",
    "‚ùå chute !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r save_actions_11\n",
    "# display_r2(save_actions_11)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save_actions_11_1\n",
    "\n",
    "BASE +  \n",
    "save_actions_11\n",
    "- filter `GHGEmissionsIntensity` <= 20 (2 individuals)\n",
    "- filter `NumberofBuildings` <= 20 (3 individuals)\n",
    "- filter `NumberofFloors` <= 40 (16 individuals)\n",
    "- filter `PropertyGFATotal` <= 2000000 (1 individual)\n",
    "- create `BuildingRatio` feature\n",
    "- drop `PropertyGFABuilding(s)` feature\n",
    "- create `AreaPerFloor(sf)` feature  \n",
    "- create `AreaPerBldg(sf)` feature\n",
    "- drop `NumberofFloors` feature\n",
    "- drop `NumberofBuildings` feature\n",
    "- filter `AreaPerFloor(sf)` <= 0.004 (1 individual)\n",
    "- create `NonResidentialRatio` feature  \n",
    "- filter `NonResidentialRatio` >= min_nr_pct (often > 1000 individuals)\n",
    "\n",
    "\\+ create `ParkingRatio` feature  \n",
    "\\+ drop `PropertyGFAParking` feature  \n",
    "\\+ filter `ParkingRatio` <= 0.8 (8 individuals)\n",
    "\n",
    "**‚û°Ô∏è 0.212**\n",
    "\n",
    "‚ÜóÔ∏è mieux mais toujours pas top : fuite pas ici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r save_actions_11_1\n",
    "# display_r2(save_actions_11_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save_actions_12\n",
    "\n",
    "BASE +  \n",
    "save_actions_7_2\n",
    "- filter `GHGEmissionsIntensity` <= 20 (2 individuals)\n",
    "- filter `NumberofBuildings` <= 20 (3 individuals)\n",
    "- filter `NumberofFloors` <= 40 (16 individuals)\n",
    "- filter `PropertyGFATotal` <= 2000000 (1 individual)\n",
    "- create `BuildingRatio` feature\n",
    "- drop `PropertyGFABuilding(s)` feature\n",
    "- create `AreaPerFloor(sf)` feature  \n",
    "- create `AreaPerBldg(sf)` feature\n",
    "- drop `NumberofFloors` feature\n",
    "- drop `NumberofBuildings` feature\n",
    "- filter `AreaPerFloor(sf)` <= 0.004 (1 individual)\n",
    "\n",
    "**TEST STEAM_USE**  \n",
    "\\+ create `SteamUse_I(kBtu/sf)` feature  \n",
    "\\+ drop `SteamUse(kBtu)` feature  \n",
    "\\+ filter `SteamUse_I(kBtu/sf)` <= 100 (6 individuals)  \n",
    "\n",
    "**‚û°Ô∏è 0.336**\n",
    "\n",
    "‚âà kif-kif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r save_actions_12\n",
    "# display_r2(save_actions_12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save_actions_13\n",
    "\n",
    "BASE +  \n",
    "save_actions_7_2\n",
    "- filter `GHGEmissionsIntensity` <= 20 (2 individuals)\n",
    "- filter `NumberofBuildings` <= 20 (3 individuals)\n",
    "- filter `NumberofFloors` <= 40 (16 individuals)\n",
    "- filter `PropertyGFATotal` <= 2000000 (1 individual)\n",
    "- create `BuildingRatio` feature\n",
    "- drop `PropertyGFABuilding(s)` feature\n",
    "- create `AreaPerFloor(sf)` feature  \n",
    "- create `AreaPerBldg(sf)` feature\n",
    "- drop `NumberofFloors` feature\n",
    "- drop `NumberofBuildings` feature\n",
    "- filter `AreaPerFloor(sf)` <= 0.004 (1 individual)\n",
    "\n",
    "**TEST ELECTRICITY**  \n",
    "\\+ create `Electricity_I(kBtu/sf)` feature  \n",
    "\\+ drop `Electricity(kBtu)` feature  \n",
    "\\+ filter `Electricity_I(kBtu/sf)` <= 350 (6 individuals)\n",
    "\n",
    "**‚û°Ô∏è 0.579**\n",
    "\n",
    "‚Üó belle augmentation (0.328 au test 7_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r save_actions_13\n",
    "# display_r2(save_actions_13)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save_actions_14\n",
    "\n",
    "BASE +  \n",
    "save_actions_7_2\n",
    "- filter `GHGEmissionsIntensity` <= 20 (2 individuals)\n",
    "- filter `NumberofBuildings` <= 20 (3 individuals)\n",
    "- filter `NumberofFloors` <= 40 (16 individuals)\n",
    "- filter `PropertyGFATotal` <= 2000000 (1 individual)\n",
    "- create `BuildingRatio` feature\n",
    "- drop `PropertyGFABuilding(s)` feature\n",
    "- create `AreaPerFloor(sf)` feature  \n",
    "- create `AreaPerBldg(sf)` feature\n",
    "- drop `NumberofFloors` feature\n",
    "- drop `NumberofBuildings` feature\n",
    "- filter `AreaPerFloor(sf)` <= 0.004 (1 individual)\n",
    "\n",
    "**TEST NATURALGAS**  \n",
    "\\+ create `NaturalGas_I(kBtu/sf)` feature  \n",
    "\\+ drop `NaturalGas(kBtu)` feature\n",
    "\n",
    "**‚û°Ô∏è 0.614**\n",
    "\n",
    "‚Üó belle augmentation (0.328 au test 7_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r save_actions_14\n",
    "# display_r2(save_actions_14)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[Enregistrement des traitements](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enregistrement des traitements dans une liste et export Pickle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo \"for Pickle saving, just exec once\"\n",
    "\n",
    "scores_list = [save_actions, save_actions_2, save_actions_3, save_actions_4,\n",
    "    save_actions_5, save_actions_6, save_actions_6_1, save_actions_6_2,\n",
    "    save_actions_7, save_actions_7_1, save_actions_7_2, save_actions_8,\n",
    "    save_actions_8_1, save_actions_8_2, save_actions_9, save_actions_9_1,\n",
    "    save_actions_10, save_actions_11, save_actions_11_1, save_actions_12,\n",
    "    save_actions_13, save_actions_14]\n",
    "\n",
    "score_names = [\"save_actions\", \"save_actions_2\", \"save_actions_3\",\n",
    "    \"save_actions_4\", \"save_actions_5\", \"save_actions_6\", \"save_actions_6_1\",\n",
    "    \"save_actions_6_2\", \"save_actions_7\", \"save_actions_7_1\",\n",
    "    \"save_actions_7_2\", \"save_actions_8\", \"save_actions_8_1\",\n",
    "    \"save_actions_8_2\", \"save_actions_9\", \"save_actions_9_1\",\n",
    "    \"save_actions_10\", \"save_actions_11\", \"save_actions_11_1\",\n",
    "    \"save_actions_12\", \"save_actions_13\", \"save_actions_14\"]\n",
    "\n",
    "for i, e in enumerate(scores_list):\n",
    "    e.insert(0, score_names[i])\n",
    "\n",
    "pickle.dump(scores_list, open(\"data_leak_scores.p\", \"wb\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc5_'></a>[Scores (r2) selon les traitements](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"4885be47-d322-4bef-ab92-12738c3b905e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4885be47-d322-4bef-ab92-12738c3b905e\")) {                    Plotly.newPlot(                        \"4885be47-d322-4bef-ab92-12738c3b905e\",                        [{\"mode\":\"lines+markers\",\"name\":\"LinReg\",\"x\":[\"save_actions\",\"save_actions_2\",\"save_actions_3\",\"save_actions_4\",\"save_actions_5\",\"save_actions_6\",\"save_actions_6_1\",\"save_actions_6_2\",\"save_actions_7\",\"save_actions_7_1\",\"save_actions_7_2\",\"save_actions_8\",\"save_actions_8_1\",\"save_actions_8_2\",\"save_actions_9\",\"save_actions_9_1\",\"save_actions_10\",\"save_actions_11\",\"save_actions_11_1\",\"save_actions_12\",\"save_actions_13\",\"save_actions_14\"],\"y\":[-3.0,-3.0,-3.0,0.075,-0.318,-0.276,-0.273,-0.471,0.023,0.066,0.066,0.513,0.513,0.859,0.859,0.934,0.962,-0.291,-0.02,0.117,0.625,0.583],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"SVR\",\"x\":[\"save_actions\",\"save_actions_2\",\"save_actions_3\",\"save_actions_4\",\"save_actions_5\",\"save_actions_6\",\"save_actions_6_1\",\"save_actions_6_2\",\"save_actions_7\",\"save_actions_7_1\",\"save_actions_7_2\",\"save_actions_8\",\"save_actions_8_1\",\"save_actions_8_2\",\"save_actions_9\",\"save_actions_9_1\",\"save_actions_10\",\"save_actions_11\",\"save_actions_11_1\",\"save_actions_12\",\"save_actions_13\",\"save_actions_14\"],\"y\":[0.21,0.466,0.459,0.459,0.44,0.454,0.453,0.279,0.459,0.462,0.462,0.614,0.615,0.869,0.871,0.934,0.963,0.513,0.537,0.501,0.713,0.641],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"RdmForestReg\",\"x\":[\"save_actions\",\"save_actions_2\",\"save_actions_3\",\"save_actions_4\",\"save_actions_5\",\"save_actions_6\",\"save_actions_6_1\",\"save_actions_6_2\",\"save_actions_7\",\"save_actions_7_1\",\"save_actions_7_2\",\"save_actions_8\",\"save_actions_8_1\",\"save_actions_8_2\",\"save_actions_9\",\"save_actions_9_1\",\"save_actions_10\",\"save_actions_11\",\"save_actions_11_1\",\"save_actions_12\",\"save_actions_13\",\"save_actions_14\"],\"y\":[-0.626,0.434,0.437,0.464,0.344,0.345,0.35,0.152,0.4,0.398,0.387,0.653,0.656,0.857,0.858,0.934,0.957,0.276,0.288,0.492,0.695,0.634],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"GradBoostReg\",\"x\":[\"save_actions\",\"save_actions_2\",\"save_actions_3\",\"save_actions_4\",\"save_actions_5\",\"save_actions_6\",\"save_actions_6_1\",\"save_actions_6_2\",\"save_actions_7\",\"save_actions_7_1\",\"save_actions_7_2\",\"save_actions_8\",\"save_actions_8_1\",\"save_actions_8_2\",\"save_actions_9\",\"save_actions_9_1\",\"save_actions_10\",\"save_actions_11\",\"save_actions_11_1\",\"save_actions_12\",\"save_actions_13\",\"save_actions_14\"],\"y\":[-1.607,0.437,0.432,0.446,-0.156,-0.122,-0.144,-0.329,0.399,0.381,0.395,0.632,0.63,0.864,0.864,0.932,0.963,-0.469,0.041,0.236,0.282,0.598],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"mean\",\"x\":[\"save_actions\",\"save_actions_2\",\"save_actions_3\",\"save_actions_4\",\"save_actions_5\",\"save_actions_6\",\"save_actions_6_1\",\"save_actions_6_2\",\"save_actions_7\",\"save_actions_7_1\",\"save_actions_7_2\",\"save_actions_8\",\"save_actions_8_1\",\"save_actions_8_2\",\"save_actions_9\",\"save_actions_9_1\",\"save_actions_10\",\"save_actions_11\",\"save_actions_11_1\",\"save_actions_12\",\"save_actions_13\",\"save_actions_14\"],\"y\":[-3.0,-3.0,-3.0,0.361,0.077,0.1,0.096,-0.092,0.32,0.327,0.328,0.603,0.604,0.862,0.863,0.934,0.961,0.007,0.212,0.336,0.579,0.614],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"median\",\"x\":[\"save_actions\",\"save_actions_2\",\"save_actions_3\",\"save_actions_4\",\"save_actions_5\",\"save_actions_6\",\"save_actions_6_1\",\"save_actions_6_2\",\"save_actions_7\",\"save_actions_7_1\",\"save_actions_7_2\",\"save_actions_8\",\"save_actions_8_1\",\"save_actions_8_2\",\"save_actions_9\",\"save_actions_9_1\",\"save_actions_10\",\"save_actions_11\",\"save_actions_11_1\",\"save_actions_12\",\"save_actions_13\",\"save_actions_14\"],\"y\":[-1.116,0.436,0.434,0.452,0.094,0.111,0.103,-0.089,0.4,0.39,0.391,0.623,0.622,0.861,0.861,0.934,0.962,-0.007,0.164,0.364,0.66,0.616],\"type\":\"scatter\"}],                        {\"yaxis\":{\"range\":[-0.5,1]},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('4885be47-d322-4bef-ab92-12738c3b905e');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_actions = BASE: drop duplicates (0), keep compliants only, clean neighborhood, drop useless feats, drop nans except ENERGYSTARScore, sort columns\n",
      "save_actions_2    = BASE + filter GHGEmissionsIntensity, NumberofBuildings, NumberofFloors, PropertyGFATotal (22)\n",
      "save_actions_3    = ........ + create BuildingRatio feature\n",
      "save_actions_4    = ............ + drop PropertyGFABuilding(s) feature\n",
      "save_actions_5    = ................ + filter BuildingRatio (19)\n",
      "save_actions_6    = .................|.. + create ParkingRatio feature\n",
      "save_actions_6_1  = .................|...... + drop PropertyGFAParking feature\n",
      "save_actions_6_2  = .................|.......... + filter ParkingRatio (8)\n",
      "save_actions_7    = ................ + create AreaPerFloor(sf) and AreaPerBldg(sf) features\n",
      "save_actions_7_1  = .................... + drop NumberofFloors and NumberofBuildings features\n",
      "save_actions_7_2  = ........................ + filter AreaPerFloor(sf) (1)\n",
      "save_actions_8    = ............................ + create SteamUse_I(kBtu/sf), Electricity_I(kBtu/sf) and NaturalGas_I(kBtu/sf) features\n",
      "save_actions_8_1  = .............................|.. + drop SteamUse(kBtu), Electricity(kBtu) and NaturalGas(kBtu) features\n",
      "save_actions_8_2  = .............................|...... + filter SteamUse_I(kBtu/sf) (6), Electricity_I(kBtu/sf) (6)\n",
      "save_actions_9    = .............................|.......... + create NonResidentialRatio feature\n",
      "save_actions_9_1  = .............................|.............. + filter NonResidentialRatio >= min_nr_pct (often > 1000)\n",
      "save_actions_10   = .............................|.................. + create ParkingRatio, drop PropertyGFAParking, filter ParkingRatio (8)\n",
      "save_actions_11   = ............................ + create NonResidentialRatio + filter >= min_nr_pct (often > 1000)\n",
      "save_actions_11_1 = .............................|.. + create ParkingRatio, drop PropertyGFAParking feature, filter ParkingRatio (8)\n",
      "save_actions_12   = ............................ + STEAMUSE: create SteamUse_I(kBtu/sf), drop SteamUse(kBtu), filter SteamUse_I(kBtu/sf) (6)\n",
      "save_actions_13   = ............................ + ELECTRICITY: create Electricity_I(kBtu/sf), drop Electricity(kBtu), filter Electricity_I(kBtu/sf) (6)\n",
      "save_actions_14   = ............................ + NATURALGAS: create NaturalGas_I(kBtu/sf), drop NaturalGas(kBtu)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores_list = pickle.load(open(\"data_leak_scores.p\", \"rb\"))\n",
    "display_all_r2(scores_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
